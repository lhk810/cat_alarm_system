{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28819,"status":"ok","timestamp":1684071091416,"user":{"displayName":"Lee HK","userId":"16545943539650080054"},"user_tz":-540},"id":"HcjdskSfdE-G","outputId":"e7055154-a3b8-4a47-9549-a3cbaf6d9419"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"HcjdskSfdE-G"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oCsuDb7dG0B"},"outputs":[],"source":["!cd 'drive/MyDrive/Colab Notebooks/'"],"id":"3oCsuDb7dG0B"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkX6GyzIdNG6"},"outputs":[],"source":["import os\n","os.chdir(\"drive/MyDrive/Colab Notebooks/\")"],"id":"XkX6GyzIdNG6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d4da00d"},"outputs":[],"source":["import glob as glob\n","import matplotlib.pyplot as plt\n","import cv2\n","import requests\n","import random\n","import numpy as np\n","\n","np.random.seed(42)"],"id":"6d4da00d"},{"cell_type":"markdown","metadata":{"id":"d7034839"},"source":["## Hyperparameters and Constants\n","\n","Here, we define wether to train the model or not and for how many epochs to train for.\n","\n","If `TRAIN = False`, then the last trained model will be used for inference in the notebook if run end to end."],"id":"d7034839"},{"cell_type":"code","execution_count":null,"metadata":{"id":"db6d5dc8"},"outputs":[],"source":["TRAIN = True\n","# Number of epochs to train for.\n","EPOCHS = 25"],"id":"db6d5dc8"},{"cell_type":"markdown","metadata":{"id":"69105c90"},"source":["### Visualize a Few Ground Truth Images\n","\n","Before moving forward, let's check out few of the ground truth images. \n","\n","The current annotations in the text files are in normalized `[x_center, y_center, width, height]` format. Let's write a function that will convert it back to `[x_min, y_min, x_max, y_max]` format."],"id":"69105c90"},{"cell_type":"code","execution_count":null,"metadata":{"id":"561f30fc"},"outputs":[],"source":["class_names = ['Lieber', 'Lieb']\n","colors = np.random.uniform(0, 255, size=(len(class_names), 3))"],"id":"561f30fc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2edd455f"},"outputs":[],"source":["# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n","def yolo2bbox(bboxes):\n","    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n","    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n","    return xmin, ymin, xmax, ymax"],"id":"2edd455f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a6b5fc8"},"outputs":[],"source":["def plot_box(image, bboxes, labels):\n","    # Need the image height and width to denormalize\n","    # the bounding box coordinates\n","    h, w, _ = image.shape\n","    for box_num, box in enumerate(bboxes):\n","        x1, y1, x2, y2 = yolo2bbox(box)\n","        # denormalize the coordinates\n","        xmin = int(x1*w)\n","        ymin = int(y1*h)\n","        xmax = int(x2*w)\n","        ymax = int(y2*h)\n","        width = xmax - xmin\n","        height = ymax - ymin\n","        \n","        class_name = class_names[int(labels[box_num])]\n","        \n","        cv2.rectangle(\n","            image, \n","            (xmin, ymin), (xmax, ymax),\n","            color=colors[class_names.index(class_name)],\n","            thickness=2\n","        ) \n","\n","        font_scale = min(1,max(3,int(w/500)))\n","        font_thickness = min(2, max(10,int(w/50)))\n","        \n","        p1, p2 = (int(xmin), int(ymin)), (int(xmax), int(ymax))\n","        # Text width and height\n","        tw, th = cv2.getTextSize(\n","            class_name, \n","            0, fontScale=font_scale, thickness=font_thickness\n","        )[0]\n","        p2 = p1[0] + tw, p1[1] + -th - 10\n","        cv2.rectangle(\n","            image, \n","            p1, p2,\n","            color=colors[class_names.index(class_name)],\n","            thickness=-1,\n","        )\n","        cv2.putText(\n","            image, \n","            class_name,\n","            (xmin+1, ymin-10),\n","            cv2.FONT_HERSHEY_SIMPLEX,\n","            font_scale,\n","            (255, 255, 255),\n","            font_thickness\n","        )\n","    return image"],"id":"4a6b5fc8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"18cba619"},"outputs":[],"source":["# Function to plot images with the bounding boxes.\n","def plot(image_paths, label_paths, num_samples):\n","    all_training_images = glob.glob(image_paths)\n","    all_training_labels = glob.glob(label_paths)\n","    all_training_images.sort()\n","    all_training_labels.sort()\n","    \n","    num_images = len(all_training_images)\n","    \n","    plt.figure(figsize=(15, 12))\n","    for i in range(num_samples):\n","        j = random.randint(0,num_images-1)\n","        image = cv2.imread(all_training_images[j])\n","        with open(all_training_labels[j], 'r') as f:\n","            bboxes = []\n","            labels = []\n","            label_lines = f.readlines()\n","            for label_line in label_lines:\n","                label = label_line[0]\n","                bbox_string = label_line[2:]\n","                x_c, y_c, w, h = bbox_string.split(' ')\n","                x_c = float(x_c)\n","                y_c = float(y_c)\n","                w = float(w)\n","                h = float(h)\n","                bboxes.append([x_c, y_c, w, h])\n","                labels.append(label)\n","        result_image = plot_box(image, bboxes, labels)\n","        plt.subplot(2, 2, i+1)\n","        plt.imshow(result_image[:, :, ::-1])\n","        plt.axis('off')\n","    plt.subplots_adjust(wspace=0)\n","    plt.tight_layout()\n","    plt.show()"],"id":"18cba619"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1fuDMojrdwE4lAfFcsQfMlRzBgqCTBjBe"},"executionInfo":{"elapsed":32510,"status":"ok","timestamp":1684071165696,"user":{"displayName":"Lee HK","userId":"16545943539650080054"},"user_tz":-540},"id":"7f9d242e","outputId":"f9f822ad-06c3-42e9-95d5-4018247864d7"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Visualize a few training images.\n","plot(\n","    image_paths='data/train/images/*', \n","    label_paths='data/train/labels/*',\n","    num_samples=4,\n",")"],"id":"7f9d242e"},{"cell_type":"markdown","metadata":{"id":"9a07c9d1"},"source":["## Helper Functions for Logging\n","\n","Here, we write the helper functions that we need for logging of the results in the notebook while training the models.\n","\n","Let's create our custom result directories so that we can easily keep track of them and carry out inference using the proper model."],"id":"9a07c9d1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a66ba3a9"},"outputs":[],"source":["def set_res_dir():\n","    # Directory to store results\n","    res_dir_count = len(glob.glob('runs/train/*'))\n","    print(f\"Current number of result directories: {res_dir_count}\")\n","    if TRAIN:\n","        RES_DIR = f\"results_{res_dir_count+1}\"\n","        print(RES_DIR)\n","    else:\n","        RES_DIR = f\"results_{res_dir_count}\"\n","    return RES_DIR"],"id":"a66ba3a9"},{"cell_type":"markdown","metadata":{"id":"20e6bd98"},"source":["## Clone YOLOV5 Repository"],"id":"20e6bd98"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0d1d163","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684071240908,"user_tz":-540,"elapsed":4015,"user":{"displayName":"Lee HK","userId":"16545943539650080054"}},"outputId":"34389e2f-3ad2-4737-b441-4b95bab09333"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15661, done.\u001b[K\n","remote: Counting objects: 100% (268/268), done.\u001b[K\n","remote: Compressing objects: 100% (167/167), done.\u001b[K\n","remote: Total 15661 (delta 138), reused 176 (delta 101), pack-reused 15393\u001b[K\n","Receiving objects: 100% (15661/15661), 14.60 MiB | 15.25 MiB/s, done.\n","Resolving deltas: 100% (10667/10667), done.\n"]}],"source":["if not os.path.exists('yolov5'):\n","    !git clone https://github.com/ultralytics/yolov5.git"],"id":"c0d1d163"},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5d51690","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684071258063,"user_tz":-540,"elapsed":466,"user":{"displayName":"Lee HK","userId":"16545943539650080054"}},"outputId":"da80d558-be1b-4c8d-c691-9fc806d8db22"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/yolov5\n","/content/drive/MyDrive/Colab Notebooks/yolov5\n"]}],"source":["%cd yolov5/\n","!pwd"],"id":"a5d51690"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5HKnG4RH4PaJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684071270069,"user_tz":-540,"elapsed":8983,"user":{"displayName":"Lee HK","userId":"16545943539650080054"}},"outputId":"33cd5a5c-d147-465f-fe24-256bb0e9e40d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.0+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.1+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (67.7.2)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.7.1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, gitdb, gitpython, thop\n","Successfully installed gitdb-4.0.10 gitpython-3.1.31 smmap-5.0.0 thop-0.1.1.post2209072238\n"]}],"source":["!pip install -r requirements.txt"],"id":"5HKnG4RH4PaJ"},{"cell_type":"markdown","metadata":{"id":"43df9ad6"},"source":["## Training using YOLOV5"],"id":"43df9ad6"},{"cell_type":"markdown","metadata":{"id":"6e1739ff"},"source":["## Training and Inference using  Medium Model"],"id":"6e1739ff"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0d8a4fa7"},"outputs":[],"source":["RES_DIR = set_res_dir()\n","if TRAIN:\n","    !python train.py --data ../data.yaml --weights yolov5m.pt \\\n","    --img 640 --epochs {EPOCHS} --batch-size 16 --name {RES_DIR}"],"id":"0d8a4fa7"}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.11.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}